{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bed2834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5514ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to calculate IoU and IoU distance matrix for SORT\n",
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union between two bounding boxes\n",
    "    bbox format: [x, y, width, height]\n",
    "    \"\"\"\n",
    "    x1, y1, width1, height1 = bbox1\n",
    "    x2, y2, width2, height2 = bbox2\n",
    "    \n",
    "    # calculate intersection\n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1 + width1, x2 + width2)\n",
    "    y_bottom = min(y1 + height1, y2 + height2)\n",
    "    \n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    bbox1_area = width1 * height1\n",
    "    bbox2_area = width2 * height2\n",
    "    union_area = bbox1_area + bbox2_area - intersection_area\n",
    "    \n",
    "    return intersection_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "def iou_distance(bboxes1, bboxes2):\n",
    "    \"\"\"\n",
    "    Calculate IoU distance matrix between two sets of bounding boxes\n",
    "    Returns a cost matrix (1 - IoU) for the Hungarian algorithm\n",
    "    \"\"\"\n",
    "    if len(bboxes1) == 0 or len(bboxes2) == 0:\n",
    "        return np.zeros((len(bboxes1), len(bboxes2)))\n",
    "    \n",
    "    cost_matrix = np.zeros((len(bboxes1), len(bboxes2)))\n",
    "    for i, bbox1 in enumerate(bboxes1):\n",
    "        for j, bbox2 in enumerate(bboxes2):\n",
    "            cost_matrix[i, j] = 1 - iou(bbox1, bbox2)\n",
    "    \n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman filter w/ constant velocity model\n",
    "class KalmanBoxTracker:\n",
    "    \"\"\"\n",
    "    Kalman filter-based tracker for bounding boxes\n",
    "    State: [x, y, width, height, velocity_x, velocity_y, velocity_width, velocity_height]\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    \n",
    "    def __init__(self, bbox):\n",
    "        \"\"\"Initialize Kalman filter with initial bounding box [x, y, width, height]\"\"\"\n",
    "        self.kf = KalmanFilter(dim_x=8, dim_z=4)\n",
    "        \n",
    "        # state transition matrix\n",
    "        self.kf.F = np.array([\n",
    "            [1, 0, 0, 0, 1, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 1, 0, 0, 0, 1],\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "        ])\n",
    "        \n",
    "        # measurement matrix\n",
    "        self.kf.H = np.array([\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "        ])\n",
    "        \n",
    "        # measurement noise\n",
    "        self.kf.R *= 10.0\n",
    "        \n",
    "        # process noise\n",
    "        self.kf.Q[-4:, -4:] *= 0.01\n",
    "        self.kf.Q[:4, :4] *= 0.01\n",
    "        \n",
    "        # initial state covariance\n",
    "        self.kf.P[4:, 4:] *= 1000.0\n",
    "        self.kf.P *= 10.0\n",
    "        \n",
    "        # initialize state\n",
    "        self.kf.x[:4] = bbox.reshape(4, 1)\n",
    "        \n",
    "        self.time_since_update = 0\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "        self.hits = 1\n",
    "        self.hit_streak = 1\n",
    "        self.age = 1\n",
    "        \n",
    "    def update(self, bbox):\n",
    "        \"\"\"Update the Kalman filter with observed bounding box\"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.hits += 1\n",
    "        self.hit_streak += 1\n",
    "        self.kf.update(bbox.reshape(4, 1))\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict the next state\"\"\"\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        self.time_since_update += 1\n",
    "        return self.get_state()\n",
    "        \n",
    "    def get_state(self):\n",
    "        \"\"\"Return the current bounding box estimate\"\"\"\n",
    "        state = self.kf.x[:4].flatten()\n",
    "        # ensure width and height are positive\n",
    "        state[2] = max(state[2], 1)\n",
    "        state[3] = max(state[3], 1)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec76d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT configs\n",
    "MAX_AGE = 25\n",
    "MIN_HITS = 3\n",
    "IOU_THRESHOLD = 0.3\n",
    "\n",
    "class SORTTracker:\n",
    "    \"\"\"\n",
    "    SORT-inspired multi-object tracker using Kalman filters and Hungarian algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD):\n",
    "        \"\"\"\n",
    "        max_age: maximum frames to keep alive a track without associated detections\n",
    "        min_hits: minimum number of associated detections before track is confirmed\n",
    "        iou_threshold: minimum IoU for matching detections to tracks\n",
    "        \"\"\"\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.trackers = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "    def update(self, detections):\n",
    "        \"\"\"\n",
    "        Update tracks with new detections\n",
    "        detections: numpy array of shape (N, 4) with format [x, y, width, height]\n",
    "        Returns: numpy array of shape (M, 5) with format [x, y, width, height, track_id]\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # get predicted locations from existing trackers\n",
    "        tracks = np.zeros((len(self.trackers), 4))\n",
    "        to_delete = []\n",
    "        for track_index, track in enumerate(tracks):\n",
    "            position = self.trackers[track_index].predict()\n",
    "            track[:] = position\n",
    "            if np.any(np.isnan(position)):\n",
    "                to_delete.append(track_index)\n",
    "        \n",
    "        # remove invalid trackers\n",
    "        for track_index in reversed(to_delete):\n",
    "            self.trackers.pop(track_index)\n",
    "        tracks = np.delete(tracks, to_delete, axis=0)\n",
    "        \n",
    "        # associate detections to trackers\n",
    "        matched, unmatched_detections, unmatched_trackers = self.associate_detections_to_trackers(\n",
    "            detections, tracks\n",
    "        )\n",
    "        \n",
    "        # update matched trackers with assigned detections\n",
    "        for match in matched:\n",
    "            self.trackers[match[1]].update(detections[match[0]])\n",
    "        \n",
    "        # create new trackers for unmatched detections\n",
    "        for detection_index in unmatched_detections:\n",
    "            tracker = KalmanBoxTracker(detections[detection_index])\n",
    "            self.trackers.append(tracker)\n",
    "        \n",
    "        # return current tracked objects\n",
    "        results = []\n",
    "        for tracker in self.trackers:\n",
    "            if tracker.time_since_update < 1 and (tracker.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "                detection = tracker.get_state()\n",
    "                results.append(np.concatenate((detection, [tracker.id])))\n",
    "        \n",
    "        # remove dead trackers\n",
    "        self.trackers = [tracker for tracker in self.trackers if tracker.time_since_update < self.max_age]\n",
    "        \n",
    "        return np.array(results) if len(results) > 0 else np.empty((0, 5))\n",
    "    \n",
    "    def associate_detections_to_trackers(self, detections, trackers):\n",
    "        \"\"\"\n",
    "        Assigns detections to tracked objects using the Hungarian algorithm\n",
    "        Returns 3 lists: matches, unmatched_detections, unmatched_trackers\n",
    "        \"\"\"\n",
    "        if len(trackers) == 0:\n",
    "            return [], list(range(len(detections))), []\n",
    "        \n",
    "        if len(detections) == 0:\n",
    "            return [], [], list(range(len(trackers)))\n",
    "        \n",
    "        # calculate IoU distance matrix\n",
    "        cost_matrix = iou_distance(detections, trackers)\n",
    "        \n",
    "        # solve assignment problem\n",
    "        row_indices, column_indices = linear_sum_assignment(cost_matrix)\n",
    "        \n",
    "        # filter out matches with low IoU\n",
    "        matches = []\n",
    "        unmatched_detections = list(range(len(detections)))\n",
    "        unmatched_trackers = list(range(len(trackers)))\n",
    "        \n",
    "        for row_index, column_index in zip(row_indices, column_indices):\n",
    "            if cost_matrix[row_index, column_index] < (1 - self.iou_threshold):\n",
    "                matches.append([row_index, column_index])\n",
    "                unmatched_detections.remove(row_index)\n",
    "                unmatched_trackers.remove(column_index)\n",
    "        \n",
    "        return matches, unmatched_detections, unmatched_trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1c8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection configs\n",
    "MIN_CONTOUR_AREA = 300\n",
    "MORPH_KERNEL_SIZE = (5, 5)\n",
    "MORPH_OPEN_ITERATIONS = 1\n",
    "MORPH_CLOSE_ITERATIONS = 2\n",
    "\n",
    "def detect_objects(frame, background_subtractor, min_area=MIN_CONTOUR_AREA):\n",
    "    \"\"\"\n",
    "    Detect objects in frame using background subtraction\n",
    "    Returns list of bounding boxes in format [x, y, width, height]\n",
    "    \"\"\"\n",
    "    # apply background subtraction\n",
    "    foreground_mask = background_subtractor.apply(frame)\n",
    "    \n",
    "    # morphological operations to reduce noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, MORPH_KERNEL_SIZE)\n",
    "    foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_OPEN, kernel, iterations=MORPH_OPEN_ITERATIONS)\n",
    "    foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel, iterations=MORPH_CLOSE_ITERATIONS)\n",
    "    \n",
    "    # find contours\n",
    "    contours, _ = cv2.findContours(foreground_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # extract bounding boxes from valid contours\n",
    "    detections = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, width, height = cv2.boundingRect(contour)\n",
    "            detections.append([x, y, width, height])\n",
    "    \n",
    "    return np.array(detections) if len(detections) > 0 else np.empty((0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8666db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background subtractor configs\n",
    "BACKGROUND_HISTORY = 500\n",
    "BACKGROUND_VAR_THRESHOLD = 16\n",
    "BACKGROUND_DETECT_SHADOWS = False\n",
    "\n",
    "# video writer \n",
    "VIDEO_CODEC = 'mp4v'\n",
    "\n",
    "# viz constants\n",
    "BBOX_THICKNESS = 2\n",
    "TEXT_FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "TEXT_SCALE = 0.6\n",
    "TEXT_THICKNESS = 2\n",
    "TEXT_Y_OFFSET = 10\n",
    "\n",
    "def process_video(video_path, output_dir, sequence_name):\n",
    "    \"\"\"\n",
    "    Process a single video file with MOT tracking\n",
    "    Returns processing time and average FPS\n",
    "    \"\"\"\n",
    "    # create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # open video\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    if not capture.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # get video properties\n",
    "    fps = int(capture.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # initialize video writer\n",
    "    output_video_path = os.path.join(output_dir, f\"{sequence_name}.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*VIDEO_CODEC)\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # initialize background subtractor and tracker\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "        history=BACKGROUND_HISTORY,\n",
    "        varThreshold=BACKGROUND_VAR_THRESHOLD,\n",
    "        detectShadows=BACKGROUND_DETECT_SHADOWS\n",
    "    )\n",
    "    tracker = SORTTracker(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "    \n",
    "    # storage for tracking results\n",
    "    tracking_results = []\n",
    "    \n",
    "    # process video\n",
    "    frame_number = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress_bar = tqdm(total=total_frames, desc=f\"Processing {sequence_name}\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_number += 1\n",
    "        \n",
    "        # detect objects\n",
    "        detections = detect_objects(frame, background_subtractor, min_area=MIN_CONTOUR_AREA)\n",
    "        \n",
    "        # update tracker\n",
    "        tracked_objects = tracker.update(detections)\n",
    "        \n",
    "        # draw bounding boxes and save results\n",
    "        for obj in tracked_objects:\n",
    "            x, y, width, height, track_id = obj\n",
    "            x, y, width, height = int(x), int(y), int(width), int(height)\n",
    "            track_id = int(track_id)\n",
    "            \n",
    "            # draw on frame\n",
    "            color = tuple(int(c) for c in np.random.RandomState(track_id).randint(0, 255, 3))\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), color, BBOX_THICKNESS)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x, y - TEXT_Y_OFFSET),\n",
    "                       TEXT_FONT, TEXT_SCALE, color, TEXT_THICKNESS)\n",
    "            \n",
    "            # save tracking result (MOT format)\n",
    "            tracking_results.append([frame_number, track_id, x, y, width, height, -1, -1, -1, -1])\n",
    "        \n",
    "        # write frame to output video\n",
    "        video_writer.write(frame)\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # cleanup\n",
    "    capture.release()\n",
    "    video_writer.release()\n",
    "    \n",
    "    # calculate metrics\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    average_fps = frame_number / processing_time if processing_time > 0 else 0\n",
    "    \n",
    "    # save tracking results to file\n",
    "    tracking_file = os.path.join(output_dir, f\"{sequence_name}.txt\")\n",
    "    np.savetxt(tracking_file, tracking_results, fmt='%d,%d,%d,%d,%d,%d,%d,%d,%d,%d')\n",
    "    \n",
    "    print(f\"Completed {sequence_name}: {frame_number} frames in {processing_time:.2f}s ({average_fps:.2f} FPS)\")\n",
    "    \n",
    "    return {\n",
    "        'sequence_name': sequence_name,\n",
    "        'total_frames': frame_number,\n",
    "        'processing_time': processing_time,\n",
    "        'average_fps': average_fps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4cc216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 video sequences to process\n",
      "\n",
      "Processing: F_20220220_1_1890_1920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1890_1920: 100%|██████████| 750/750 [00:31<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1890_1920: 750 frames in 31.11s (24.11 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1920_1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1920_1950: 100%|██████████| 750/750 [00:28<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1920_1950: 750 frames in 28.91s (25.95 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1680_1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1680_1710: 100%|██████████| 750/750 [00:28<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1680_1710: 750 frames in 28.95s (25.91 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1770_1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1770_1800: 100%|██████████| 750/750 [00:29<00:00, 25.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1770_1800: 750 frames in 29.29s (25.61 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1950_1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1950_1980: 100%|██████████| 750/750 [00:28<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1950_1980: 750 frames in 28.41s (26.40 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1830_1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1830_1860: 100%|██████████| 750/750 [00:30<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1830_1860: 750 frames in 30.59s (24.52 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1740_1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1740_1770: 100%|██████████| 750/750 [00:28<00:00, 26.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1740_1770: 750 frames in 28.78s (26.06 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1860_1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1860_1890: 100%|██████████| 750/750 [00:29<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1860_1890: 750 frames in 29.68s (25.27 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1800_1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1800_1830: 100%|██████████| 750/750 [00:29<00:00, 25.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1800_1830: 750 frames in 29.87s (25.11 FPS)\n",
      "\n",
      "Processing: F_20220220_1_1710_1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F_20220220_1_1710_1740: 100%|██████████| 750/750 [00:28<00:00, 26.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed F_20220220_1_1710_1740: 750 frames in 28.77s (26.07 FPS)\n",
      "\n",
      "Total sequences processed: 10\n",
      "Results saved to: ../results/classical\n",
      "Metrics saved to: ../results/classical/metrics.json\n",
      "\n",
      "Total processing time: 294.35s\n",
      "Average FPS across all sequences: 25.50\n"
     ]
    }
   ],
   "source": [
    "# path cofigs \n",
    "TEST_DIR = \"../data/soccer_side/test\"\n",
    "RESULTS_DIR = \"../results/classical\"\n",
    "VIDEO_FILENAME = \"img1.mp4\" # name of videos in teamtrack dataset\n",
    "METRICS_FILENAME = \"metrics.json\"\n",
    "\n",
    "def run_classical_method():\n",
    "    \"\"\"\n",
    "    Main function to process all videos\n",
    "    \"\"\"\n",
    "    # find all video sequences\n",
    "    video_sequences = []\n",
    "    for item in os.listdir(TEST_DIR):\n",
    "        sequence_dir = os.path.join(TEST_DIR, item)\n",
    "        if os.path.isdir(sequence_dir):\n",
    "            video_path = os.path.join(sequence_dir, VIDEO_FILENAME)\n",
    "            if os.path.exists(video_path):\n",
    "                video_sequences.append((item, video_path))\n",
    "    \n",
    "    print(f\"Found {len(video_sequences)} video sequences to process\")\n",
    "    \n",
    "    # process each video\n",
    "    all_metrics = []\n",
    "    for sequence_name, video_path in video_sequences:\n",
    "        print(f\"\\nProcessing: {sequence_name}\")\n",
    "        output_dir = os.path.join(RESULTS_DIR, sequence_name)\n",
    "        \n",
    "        metrics = process_video(video_path, output_dir, sequence_name)\n",
    "        if metrics:\n",
    "            all_metrics.append(metrics)\n",
    "    \n",
    "    # save overall metrics\n",
    "    metrics_file = os.path.join(RESULTS_DIR, METRICS_FILENAME)\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(all_metrics, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nTotal sequences processed: {len(all_metrics)}\")\n",
    "    print(f\"Results saved to: {RESULTS_DIR}\")\n",
    "    print(f\"Metrics saved to: {metrics_file}\")\n",
    "    \n",
    "    # print summary\n",
    "    if all_metrics:\n",
    "        total_time = sum(metric['processing_time'] for metric in all_metrics)\n",
    "        average_fps = sum(metric['average_fps'] for metric in all_metrics) / len(all_metrics)\n",
    "        print(f\"\\nTotal processing time: {total_time:.2f}s\")\n",
    "        print(f\"Average FPS across all sequences: {average_fps:.2f}\")\n",
    "\n",
    "# run main function\n",
    "run_classical_method()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
